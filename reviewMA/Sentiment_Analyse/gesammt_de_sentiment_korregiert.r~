# Sentiment Analysis 

setwd("/home/wei/Dropbox/Master Arbeit/reviewMA/Sentiment_Analyse") 
pdf("result/gesammt_de_sentiment.pdf")
sink("result/gesammt_de_sentiment.txt", append=TRUE)

PandN_words <-readLines("SentiWS.txt", encoding = "UTF-8")
PandN_words <-unlist(strsplit(PandN_words, ","))
PandN_words <- tolower(PandN_words)
#PandN_number=dim(PandN_words)[1]
require(plyr)
require(stringr)
library(tm)


score.sentiment = function(sentences, PandN_words, .progress='none')
         { 
          require(plyr)
          require(stringr)
           scores = laply(sentences, function(sentence, PandN_words) 
           {
            docs <- Corpus(VectorSource(sentence))
            ###
            ### Text transformation
            ###
            toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
            docs <- tm_map(docs, toSpace, "/")
            docs <- tm_map(docs, toSpace, "@")
            docs <- tm_map(docs, toSpace, "\\|")

            ###
            ### Cleaning the text
            ###
            # Convert the text to lower case
            docs <- tm_map(docs, content_transformer(tolower))

            # Remove numbers
            docs <- tm_map(docs, removeNumbers)

            # Remove common stopwords
            docs <- tm_map(docs, removeWords, stopwords("german"))

            # Remove your own stop word
            # specify your stopwords as a character vector
            docs <- tm_map(docs, removeWords, c("schon", "beim")) 

            # Remove punctuations
            docs <- tm_map(docs, removePunctuation)

            # Eliminate extra white spaces
            docs <- tm_map(docs, stripWhitespace)

            # Text stemming
            docs <- tm_map(docs,stemDocument,language="german")
            dataframe<-data.frame(text=unlist(sapply(docs, `[`, "content")), stringsAsFactors=F)
            word.list = str_split(dataframe, '\\s+')
            # sometimes a list() is one level of hierarchy too much
            words = unlist(word.list)
            scoreNumber = 0
            for (word in words) {
                result = match(word, PandN_words)
                if(!is.na(result)){
                       id = as.numeric(result) + 1
                       scoreNumber = scoreNumber + as.numeric(PandN_words[id])
                }
            }
            return(scoreNumber)
           }, 
         PandN_words, .progress=.progress )
         scores.df = data.frame(score=scores, text=sentences)
         return(scores.df)
        }

    # and to see if it works, there should be a score...either in German or in English

#sample <- c("ich liebe dich. du bist wunderbar",
#            "Ich hasse dich, geh sterben!", 
#            "gut gutes schlecht positives Ware .",
#            "nicht mehr kaufen best glÃ¼cklich.")
#(test.sample <- score.sentiment(sample, PandN_words))

Daten <-read.csv("gesammt_de.csv", header=TRUE,fileEncoding = "UTF-8", sep = ",")
n=dim(Daten)[1]

###
### Select comments
###
Comments <- matrix(1,n,1)
for (i in 1:n){
  if (Daten[i,6]>=0){  
    Comments[i]=paste(Daten[i,7],Daten[i,8]) 
                    }
              }


a <- score.sentiment(Comments, PandN_words)
Scores=a$score


Sterne=Daten[,6]
plot(Sterne,Scores)
title("Vergleich")
Scores
mean(Sterne)
mean(Scores)
var(Sterne)
var(Scores)
cov(Scores,Sterne)
cor(Scores,Sterne)
cor(Scores,Sterne)
table(Sterne, Scores)

sink()
dev.off()
